{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "significant-asset",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-e036c078ba5b>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-e036c078ba5b>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    data1: mean=50.303 stdv=4.426\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# generate gaussian data samples\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two sets of univariate observations\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# summarize\n",
    "print('data1: mean=%.3f stdv=%.3f' % (mean(data1), std(data1)))\n",
    "print('data2: mean=%.3f stdv=%.3f' % (mean(data2), std(data2)))\n",
    "data1: mean=50.303 stdv=4.426\n",
    "data2: mean=51.764 stdv=4.660\n",
    "The Mann-Whitney U test (for two independent samples)\n",
    "The Mann-Whitney U test is a nonparametric statistical significance test for determining whether two independent samples were drawn from a population with the same distribution.\n",
    "More specifically, the test determines whether it is equally likely that any randomly selected observation from one sample will be greater or less than a sample in the other distribution. If violated, it suggests differing distributions.\n",
    "\n",
    "Fail to Reject H0: Sample distributions are equal.\n",
    "Reject H0: Sample distributions are not equal.\n",
    "from scipy.stats import mannwhitneyu\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')\n",
    "Statistics=4025.000, p=0.009\n",
    "Different distribution (reject H0)\n",
    "Wilcoxon Signed-Rank Test (for two paired samples/ one sample)\n",
    "The samples are related or matched in some way or represent two measurements of the same technique. More specifically, each sample is independent, but comes from the same population.\n",
    "\n",
    "The Wilcoxon signed ranks test is a nonparametric statistical procedure for comparing two samples that are paired, or related.\n",
    "The parametric equivalent to the Wilcoxon signed ranks test goes by names such as the Studentâ€™s t-test, t-test for matched pairs, t-test for paired samples, or t-test for dependent samples.\n",
    "The default assumption for the test, the null hypothesis, is that the two samples have the same distribution.\n",
    "\n",
    "Fail to Reject H0: Sample distributions are equal.\n",
    "Reject H0: Sample distributions are not equal.\n",
    "For the test to be effective, it requires at least 20 observations in each data sample.\n",
    "\n",
    "two paired samples (e.g. before and after treatments)\n",
    "from scipy.stats import wilcoxon\n",
    "# compare samples\n",
    "stat, p = wilcoxon(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')\n",
    "Statistics=1886.000, p=0.028\n",
    "Different distribution (reject H0)\n",
    "one sample: testing the difference between the two samples\n",
    "stat, p = wilcoxon(data1-data2)\n",
    "\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')\n",
    "Statistics=1886.000, p=0.028\n",
    "Different distribution (reject H0)\n",
    "Kruskal-Wallis H Test (ANOVA: for more than two independent samples)\n",
    "The Kruskal-Wallis test is a nonparametric version of the one-way analysis of variance test or ANOVA for short. It is named for the developers of the method, William Kruskal and Wilson Wallis. This test can be used to determine whether more than two independent samples have a different distribution. It can be thought of as the generalization of the Mann-Whitney U test.\n",
    "\n",
    "When the Kruskal-Wallis H-test leads to significant results, then at least one of the samples is different from the other samples. However, the test does not identify where the difference(s) occur. Moreover, it does not identify how many differences occur. To identify the particular differences between sample pairs, a researcher might use sample contrasts, or post hoc tests, to analyze the specific sample pairs for significant difference(s). The Mann-Whitney U-test is a useful method for performing sample contrasts between individual sample sets.\n",
    "\n",
    "Fail to Reject H0: All sample distributions are equal.\n",
    "Reject H0: One or more sample distributions are not equal.\n",
    "import numpy as np\n",
    "data1 = np.random.randn(100)*5 + 50\n",
    "data2 = np.random.randn(100)*5 + 50\n",
    "data3 = np.random.randn(100)*5 + 52\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "stats,p=kruskal(data1,data2,data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "alpha=0.05\n",
    "\n",
    "if p>alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')\n",
    "Statistics=1886.000, p=0.001\n",
    "Different distribution (reject H0)\n",
    "Friedman Test (repeated measures ANOVA: for more than two paired samples)\n",
    "The test assumes two or more paired data samples with 10 or more samples per group.\n",
    "\n",
    "The Friedman test is a nonparametric statistical procedure for comparing more than two samples that are related. The parametric equivalent to this test is the repeated measures analysis of variance (ANOVA). When the Friedman test leads to significant results, at least one of the samples is different from the other samples.\n",
    "\n",
    "The default assumption, or null hypothesis, is that the multiple paired samples have the same distribution. A rejection of the null hypothesis indicates that one or more of the paired samples has a different distribution.\n",
    "\n",
    "Fail to Reject H0: Paired sample distributions are equal.\n",
    "Reject H0: Paired sample distributions are not equal.\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate three independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 52\n",
    "# compare samples\n",
    "stat, p = friedmanchisquare(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n",
    "Statistics=9.360, p=0.009\n",
    "Different distributions (reject H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-panic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
