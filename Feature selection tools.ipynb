{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation\n",
    "\n",
    "Preliminary code to download clean and split the demo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0185ba5597ab4898915908132239a544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/190711 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJECT = \"uw-data-warehouse-prod\"\n",
    "TABLE = \"partner_position_master_data_v5\"\n",
    "raw_data = download_data(PROJECT, table=TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates, conts, cats = raw_data.dates_conts_cats_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['fold', 'is_live', 'is_live_plus_3m', 'partner_position_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_numeric_features = [\n",
    "    'avg_monthly_amount_paid_last_1y',\n",
    " 'avg_monthly_ri_earned_last_1y',\n",
    " 'avg_monthly_ldb_paid_last_1y',\n",
    " 'avg_monthly_supporting_bonus_paid_last_1y_pre_oct20',\n",
    " 'avg_monthly_supporting_bonus_paid_last_1y_post_oct20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionables = ['training_completed_count_last_1y', 'supported_sign_ups_in_first_45_days',\n",
    "              'remote_jtc_completion_pcnt_total', 'remote_jtc_completion_pcnt_last_1y',\n",
    "              'remote_jtc_completion_pcnt_last_3m', 'remote_jtc_completion_pcnt_last_1m',\n",
    "              'f2f_jtc_completion_pcnt_total', 'f2f_jtc_completion_pcnt_last_1y', 'days_logged_into_portal_last_3m',\n",
    "              'jtc_applications_last_3m', 'started_at_month', 'pcnt_customers_gathered_cancelled_last_3m']\n",
    "\n",
    "new_actionables = [\n",
    "    'team_building_unique_days_viewed_last_6m',\n",
    "    'team_building_unique_days_viewed_last_3m',\n",
    "    'team_building_unique_days_viewed_last_1m',\n",
    "    'customers_unique_days_viewed_last_6m',\n",
    "    'customers_unique_days_viewed_last_3m',\n",
    "    'customers_unique_days_viewed_last_1m',\n",
    "    'training_unique_days_viewed_last_6m',\n",
    "    'training_unique_days_viewed_last_3m',\n",
    "    'training_unique_days_viewed_last_1m',\n",
    "    'prospects_unique_days_viewed_last_6m',\n",
    "    'prospects_unique_days_viewed_last_3m',\n",
    "    'prospects_unique_days_viewed_last_1m',\n",
    "    'incentives_unique_days_viewed_last_6m',\n",
    "    'incentives_unique_days_viewed_last_3m',\n",
    "    'incentives_unique_days_viewed_last_1m',\n",
    "    'articles_unique_days_viewed_last_6m',\n",
    "    'articles_unique_days_viewed_last_3m',\n",
    "    'articles_unique_days_viewed_last_1m',\n",
    "    'uw_engagement_unique_days_viewed_last_6m',\n",
    "    'uw_engagement_unique_days_viewed_last_3m',\n",
    "    'uw_engagement_unique_days_viewed_last_1m',\n",
    "    'learning_plans_started_last_1y',\n",
    "    'learning_plans_started_last_3m',\n",
    "    'learning_plans_started_last_1m',\n",
    "    'learning_plans_completed_last_1y',\n",
    "    'learning_plans_completed_last_3m',\n",
    "    'learning_plans_completed_last_1m',\n",
    "    'days_since_last_learning_plan_interaction',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ords = ['title', 'status', 'times_paid_commission_last_6m', \n",
    "        'times_paid_commission_last_1y', 'times_clawback_paid_last_3m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['pcnt_customers_double_gold_total_plus_3m',\n",
    "           'pcnt_customers_homeowners_total_plus_3m',\n",
    "           'customers_gathered_total_plus_3m_delta',\n",
    "           'partners_recruited_total_plus_3m_delta']\n",
    "\n",
    "\n",
    "target = 'customers_gathered_total_plus_3m_delta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_filter = raw_data.is_live & raw_data.is_live_plus_3m  & (raw_data.elapsed_days_since_joined >= 274) & (raw_data.elapsed_days_since_joined < 679) \n",
    "activity_filter = ((raw_data.customers_gathered_last_1y + raw_data.partners_recruited_last_1y) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of the partners based on fold 3\n",
    "raw_data['is_valid'] = raw_data.fold == 3\n",
    "cohort_data = raw_data.loc[cohort_filter & activity_filter].reset_index(drop=True).copy()\n",
    "\n",
    "def split_df(df, test_random_state=None):\n",
    "    train = df[df.is_valid == 0].drop_cols('is_valid', inplace=False).reset_index(drop=True)\n",
    "    valid = df[df.is_valid == 1].drop_cols('is_valid', inplace=False).reset_index(drop=True)\n",
    "    if test_random_state is not None:\n",
    "        N = len(valid) // 2\n",
    "        reshuffled = valid.sample(frac=1., random_state=test_random_state)\n",
    "        valid, test = reshuffled.iloc[: N].reset_index(drop=True), reshuffled.iloc[N: ].reset_index(drop=True)\n",
    "        return train, valid, test\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "@patch\n",
    "def add_datepart(dataframe: pd.DataFrame, date_fields, prefix=None, drop=True, time=False):\n",
    "    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n",
    "    df = dataframe.copy()\n",
    "    for field_name in date_fields:\n",
    "        field = df[field_name]\n",
    "        prefix = re.sub('[Dd]ate$', '', field_name) if prefix is None else prefix\n",
    "        attr = ['Year', 'Month', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n",
    "                'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "        if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "        df[prefix + 'Week'] = field.dt.isocalendar().week\n",
    "        for n in attr: df[prefix + n] = getattr(field.dt, n.lower())    \n",
    "        df[prefix + 'Elapsed'] = field.astype(np.int64) // 10 ** 9\n",
    "        if drop: df.drop(field_name, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before splitting into train/valid/test\n",
    "preprocessed_data = cohort_data.add_datepart(dates).cast_types(extra_columns=to_numeric_features, inplace=False)\n",
    "for t in targets: preprocessed_data[t] = preprocessed_data[t] > 0\n",
    "\n",
    "_, conts, cats = preprocessed_data.dates_conts_cats_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def inpute_continuous_variables(df: pd.DataFrame, cont_vars):\n",
    "    inputed_values = df.loc[~df.is_valid, cont_vars].median()\n",
    "    for c in cont_vars: df[c].fillna(inputed_values[c].astype(int if is_integer_dtype(df[c].dtype) else float), inplace=True)\n",
    "    return inputed_values\n",
    "\n",
    "@patch\n",
    "def numericalise_categorical_variables(df: pd.DataFrame, cat_vars):\n",
    "    categorised = df.loc[~df.is_valid, cat_vars].copy().astype('category')\n",
    "    cat_dict = {c: sorted(categorised[c].cat.categories) for c in cat_vars if not df[c].dtype == bool}\n",
    "    for c, cats in cat_dict.items():\n",
    "        df[c] = pd.Categorical(df[c], categories=cats, ordered=True)\n",
    "        df[c] = df[c].cat.codes\n",
    "    return cat_dict\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputed_vals = preprocessed_data.inpute_continuous_variables(conts)\n",
    "categories_dict = preprocessed_data.numericalise_categorical_variables(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped_data = preprocessed_data.drop_cols(to_drop + [t for t in targets if t != target])\n",
    "# train, valid, test = split_df(prepped_data, test_random_state=92)\n",
    "train, valid  = split_df(prepped_data, test_random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance(df, target, ratio=3):\n",
    "    N = df[target].sum()\n",
    "    result = df.sort_values(target).tail(N * (ratio + 1)).copy()\n",
    "    return result.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "def split_target(df, target): return df.drop(target, axis=1), df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train = rebalance(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_target(balanced_train, target)\n",
    "X_valid, y_valid = split_target(valid, target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: normalising variables.\n",
    "\n",
    "This is not really needed for tree based model, but for the sake of demonstration, this is how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_column(df, col, mn=None, std=None):\n",
    "    \"\"\"Normalise column col.\n",
    "    If mean and std are passed, \n",
    "    it will use them for normalisation (for the validation set)\"\"\"\n",
    "    mn = df[col].mean() if mn is None else mn\n",
    "    std = df[col].std() if std is None else std\n",
    "    df[col] =  (df[col] - mn) / std\n",
    "\n",
    "    return mn, std\n",
    "\n",
    "\n",
    "def normalise_continuous_variables(train, valid, continuous_cols):\n",
    "    for c in [c for c in continuous_cols if c in train.columns]:\n",
    "        mn, std = normalise_column(train, c)\n",
    "        mn, std = normalise_column(valid, c, mn, std)\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6256006286492616, 0.3249209964944291)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['pcnt_customers_double_gold_total'].mean(), X_train['pcnt_customers_double_gold_total'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_continuous_variables(X_train, X_valid, conts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.9541320370310924e-17, 0.999999999999991)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['pcnt_customers_double_gold_total'].mean(), X_train['pcnt_customers_double_gold_total'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection: volatility control \n",
    "\n",
    "Quick and safe way to reduce the number of features: drop 0 variance columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_volatility_selection(df, var_threshold=0.):\n",
    "    \"\"\"Drops features with variance that is not above the\n",
    "    var_threshold and return the remaining dataframe\"\"\"\n",
    "    _feats = df.columns[df.var() > var_threshold].tolist()\n",
    "    return _feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove 0 variance features\n",
    "feats = control_volatility_selection(X_train)\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection: Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q boruta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boruta_selector(classifier=True):\n",
    "    from boruta import BorutaPy\n",
    "    from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "    \n",
    "    args = dict(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "    rf = RandomForestClassifier(**args) if classifier else RandomForestRegressor(**args)\n",
    "    \n",
    "    return BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "def boruta_selection(X, y, classifier=True, strict=False):\n",
    "    selector = get_boruta_selector(classifier)\n",
    "    selector.fit(X.values, y.values)\n",
    "    support = selector.support_\n",
    "    if not strict: support = support | selector.support_weak_\n",
    "    return pd.Series(X.columns).loc[support].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t146\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t146\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t146\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t146\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t146\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t146\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t146\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t24\n",
      "Rejected: \t77\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t24\n",
      "Rejected: \t77\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t24\n",
      "Rejected: \t77\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t24\n",
      "Rejected: \t77\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t19\n",
      "Rejected: \t82\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t19\n",
      "Rejected: \t82\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t19\n",
      "Rejected: \t82\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t19\n",
      "Rejected: \t82\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t16\n",
      "Rejected: \t85\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t16\n",
      "Rejected: \t85\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t16\n",
      "Rejected: \t85\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t16\n",
      "Rejected: \t85\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t16\n",
      "Rejected: \t85\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t16\n",
      "Rejected: \t85\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t13\n",
      "Rejected: \t88\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t13\n",
      "Rejected: \t88\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t13\n",
      "Rejected: \t88\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t13\n",
      "Rejected: \t88\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t13\n",
      "Rejected: \t88\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t89\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t89\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t89\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t89\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t89\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t7\n",
      "Rejected: \t94\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t7\n",
      "Rejected: \t94\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t7\n",
      "Rejected: \t94\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t6\n",
      "Rejected: \t95\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t6\n",
      "Rejected: \t95\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t6\n",
      "Rejected: \t95\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t6\n",
      "Rejected: \t95\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t6\n",
      "Rejected: \t95\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t4\n",
      "Rejected: \t97\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t4\n",
      "Rejected: \t97\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t4\n",
      "Rejected: \t97\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t3\n",
      "Rejected: \t98\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t1\n",
      "Rejected: \t98\n"
     ]
    }
   ],
   "source": [
    "boruta_feats = boruta_selection(X_train.loc[:, feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = boruta_feats\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features selection: $\\chi ^ 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_selection(X, y, cats, alpha=0.05):\n",
    "    \"\"\"Warning! Only for classification tasks\"\"\"\n",
    "    from sklearn.feature_selection import chi2\n",
    "    import pandas as pd\n",
    "    feats = [c for c in cats if c in X.columns]\n",
    "    _df = X.loc[:, feats].copy()\n",
    "    #encode variables\n",
    "    for c in _df.columns: _df[c] = _df[c].astype('category').cat.codes\n",
    "    c, p = chi2(_df, y)\n",
    "    df = pd.DataFrame({'chi_stats': c, 'p_val': p}, index=feats)\n",
    "    df['selected'] = df['p_val'] < alpha\n",
    "    return df.sort_values('p_val').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chi_stats</th>\n",
       "      <th>p_val</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_activated</th>\n",
       "      <td>275.874259</td>\n",
       "      <td>5.952373e-62</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_to_get_activated_null_reason</th>\n",
       "      <td>96.060306</td>\n",
       "      <td>1.114368e-22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    chi_stats         p_val  selected\n",
       "is_activated                       275.874259  5.952373e-62      True\n",
       "days_to_get_activated_null_reason   96.060306  1.114368e-22      True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_square_selection(X_train.loc[:, feats], y_train, cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and multicolinearity reduction: VIF\n",
    "\n",
    "Once again, this is not really needed for tree based models, but it is useful otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.astype(float).values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif.sort_values(\"VIF\").reset_index(drop=True))\n",
    "\n",
    "def vif_selection(df, vif_threshold=10.):\n",
    "    vif_df = calc_vif(df)\n",
    "    return vif_df.loc[vif_df.VIF <= vif_threshold, 'variables'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/statsmodels/stats/outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "feats = vif_selection(X_train.loc[:, feats].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection: pairwise correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_corr_selection(df, threshold=.9):\n",
    "    corrmat = df.corr().abs() \n",
    "    mask = corrmat <= threshold\n",
    "    mask |= np.triu(np.ones_like(corrmat)).astype(bool)\n",
    "    feats = mask.columns[mask.all()].tolist()\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Low correlation threshold for demo purposes\n",
    "\n",
    "corr_feats = pairwise_corr_selection(X_train.loc[:, feats], .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corr_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jtc_completion_pcnt_total',\n",
       " 'learning_plans_completed_last_1y',\n",
       " 'learning_plans_started_last_3m',\n",
       " 'pcnt_customers_double_gold_last_3m',\n",
       " 'jtc_completion_pcnt_last_3m',\n",
       " 'jtc_completion_pcnt_last_1m',\n",
       " 'group_customer_count',\n",
       " 'pcnt_customers_gathered_live_last_1m',\n",
       " 'avg_monthly_ri_earned_last_1y',\n",
       " 'training_unique_days_viewed_last_3m',\n",
       " 'avg_monthly_amount_paid_last_1y',\n",
       " 'training_unique_days_viewed_last_6m',\n",
       " 'uw_engagement_unique_days_viewed_last_1m',\n",
       " 'pcnt_customers_gathered_live_last_3m',\n",
       " 'customers_gathered_last_1m']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with MRMR\n",
    "\n",
    "This is an implementation of Uber's MRMR algorithm (see e.g. https://towardsdatascience.com/mrmr-explained-exactly-how-you-wished-someone-explained-to-you-9cf4ed27458b). This algorithm balances feature importance and minimising correlation, so it is probably to be used instead of most of the techniques shown so far. I have had decent success by applying Boruta first and then this one on datasets with a big number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boruta_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Number of features to select\n",
    "K = 15\n",
    "\n",
    "\n",
    "X = X_train.loc[:, boruta_feats].copy().astype('float32')\n",
    "y = y_train.copy()\n",
    "\n",
    "# Original version uses the linear regression tests to establish columns importances\n",
    "# F = pd.Series(f_regression(X, y)[0], index = X.columns)\n",
    "\n",
    "# This implementation uses random forests, which make less assumption on the shape of the data\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "rf.fit(X, y)\n",
    "F = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "\n",
    "# A possible alternative is using Spearman's correlation\n",
    "corr = pd.DataFrame(.00001, index = X.columns, columns = X.columns)\n",
    "\n",
    "\n",
    "selected = []\n",
    "not_selected = X.columns.to_list()\n",
    "scores = []\n",
    "\n",
    "# repeat K times\n",
    "for i in range(min(K, len(X.columns))):\n",
    "  \n",
    "    # compute (absolute) correlations between the last selected feature and all the (currently) excluded features\n",
    "    if i > 0:\n",
    "        last_selected = selected[-1]\n",
    "        corr.loc[not_selected, last_selected] = X[not_selected].corrwith(X[last_selected], \n",
    "                                                                         method='spearman').abs().clip(.00001)\n",
    "        \n",
    "    # compute FCQ score for all the (currently) excluded features (this is Formula 2)\n",
    "    score = F.loc[not_selected] / corr.loc[not_selected, selected].mean(axis = 1).fillna(.00001)\n",
    "    \n",
    "    # find best feature, add it to selected and remove it from not_selected\n",
    "    best = score.index[score.argmax()]\n",
    "    scores.append(score.max())\n",
    "    selected.append(best)\n",
    "    not_selected.remove(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jtc_applications_last_1m',\n",
       " 'days_logged_into_portal_last_3m',\n",
       " 'last_activity_Dayofyear',\n",
       " 'days_since_last_activity',\n",
       " 'days_logged_into_portal_last_1m',\n",
       " 'jtc_applications_last_3m',\n",
       " 'last_activity_Elapsed',\n",
       " 'customers_unique_days_viewed_last_3m',\n",
       " 'articles_unique_days_viewed_last_1m',\n",
       " 'last_activity_Week',\n",
       " 'team_building_unique_days_viewed_last_6m',\n",
       " 'jtc_completion_pcnt_total',\n",
       " 'articles_unique_days_viewed_last_3m',\n",
       " 'uw_engagement_unique_days_viewed_last_3m',\n",
       " 'articles_unique_days_viewed_last_6m']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
